{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOW0VFIFPYng5huEmMLOf6n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"Nfe3FNQT2WqW","executionInfo":{"status":"error","timestamp":1667888749561,"user_tz":-540,"elapsed":4505,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"3dfe17ab-4a9e-432c-e1e1-29cf0eda6baf"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e2fe73ee597a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_util\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["\"\"\" Sample TensorFlow XML-to-TFRecord converter\n","\n","usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  -x XML_DIR, --xml_dir XML_DIR\n","                        Path to the folder where the input .xml files are stored.\n","  -l LABELS_PATH, --labels_path LABELS_PATH\n","                        Path to the labels (.pbtxt) file.\n","  -o OUTPUT_PATH, --output_path OUTPUT_PATH\n","                        Path of output TFRecord (.record) file.\n","  -i IMAGE_DIR, --image_dir IMAGE_DIR\n","                        Path to the folder where the input image files are stored. Defaults to the same directory as XML_DIR.\n","  -c CSV_PATH, --csv_path CSV_PATH\n","                        Path of output .csv file. If none provided, then no file will be written.\n","\"\"\"\n","\n","import os\n","import glob\n","import pandas as pd\n","import io\n","import xml.etree.ElementTree as ET\n","import argparse\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import tensorflow.compat.v1 as tf\n","from PIL import Image\n","from object_detection.utils import dataset_util, label_map_util\n","from collections import namedtuple\n","\n","# Initiate argument parser\n","parser = argparse.ArgumentParser(\n","    description=\"Sample TensorFlow XML-to-TFRecord converter\")\n","parser.add_argument(\"-x\",\n","                    \"--xml_dir\",\n","                    help=\"Path to the folder where the input .xml files are stored.\",\n","                    type=str)\n","parser.add_argument(\"-l\",\n","                    \"--labels_path\",\n","                    help=\"Path to the labels (.pbtxt) file.\", type=str)\n","parser.add_argument(\"-o\",\n","                    \"--output_path\",\n","                    help=\"Path of output TFRecord (.record) file.\", type=str)\n","parser.add_argument(\"-i\",\n","                    \"--image_dir\",\n","                    help=\"Path to the folder where the input image files are stored. \"\n","                         \"Defaults to the same directory as XML_DIR.\",\n","                    type=str, default=None)\n","parser.add_argument(\"-c\",\n","                    \"--csv_path\",\n","                    help=\"Path of output .csv file. If none provided, then no file will be \"\n","                         \"written.\",\n","                    type=str, default=None)\n","\n","args = parser.parse_args()\n","\n","if args.image_dir is None:\n","    args.image_dir = args.xml_dir\n","\n","label_map = label_map_util.load_labelmap(args.labels_path)\n","label_map_dict = label_map_util.get_label_map_dict(label_map)\n","\n","\n","def xml_to_csv(path):\n","    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n","    them in a single Pandas dataframe.\n","\n","    Parameters:\n","    ----------\n","    path : str\n","        The path containing the .xml files\n","    Returns\n","    -------\n","    Pandas DataFrame\n","        The produced dataframe\n","    \"\"\"\n","\n","    xml_list = []\n","    for xml_file in glob.glob(path + '/*.xml'):\n","        tree = ET.parse(xml_file)\n","        root = tree.getroot()\n","        filename = root.find('filename').text\n","        width = int(root.find('size').find('width').text)\n","        height = int(root.find('size').find('height').text)\n","        for member in root.findall('object'):\n","            bndbox = member.find('bndbox')\n","            xminf = float(bndbox.find('xmin').text)\n","            yminf = float(bndbox.find('ymin').text)\n","            xmaxf = float(bndbox.find('xmax').text)\n","            ymaxf = float(bndbox.find('ymax').text)\n","            value = (filename,\n","                     width,\n","                     height,\n","                     member.find('name').text,\n","                     int(xminf),\n","                     int(yminf),\n","                     int(xmaxf),\n","                     int(ymaxf),\n","                    #  int(bndbox.find('xmin').text),\n","                    #  int(bndbox.find('ymin').text),\n","                    #  int(bndbox.find('xmax').text),\n","                    #  int(bndbox.find('ymax').text),\n","                     )\n","            xml_list.append(value)\n","    column_name = ['filename', 'width', 'height',\n","                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","    return xml_df\n","\n","\n","def class_text_to_int(row_label):\n","    return label_map_dict[row_label]\n","\n","\n","def split(df, group):\n","    data = namedtuple('data', ['filename', 'object'])\n","    gb = df.groupby(group)\n","    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","\n","def create_tf_example(group, path):\n","    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","        encoded_jpg = fid.read()\n","    encoded_jpg_io = io.BytesIO(encoded_jpg)\n","    image = Image.open(encoded_jpg_io)\n","    width, height = image.size\n","\n","    filename = group.filename.encode('utf8')\n","    image_format = b'jpg'\n","    xmins = []\n","    xmaxs = []\n","    ymins = []\n","    ymaxs = []\n","    classes_text = []\n","    classes = []\n","\n","    for index, row in group.object.iterrows():\n","        xmins.append(row['xmin'] / width)\n","        xmaxs.append(row['xmax'] / width)\n","        ymins.append(row['ymin'] / height)\n","        ymaxs.append(row['ymax'] / height)\n","        classes_text.append(row['class'].encode('utf8'))\n","        classes.append(class_text_to_int(row['class']))\n","\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","        'image/height': dataset_util.int64_feature(height),\n","        'image/width': dataset_util.int64_feature(width),\n","        'image/filename': dataset_util.bytes_feature(filename),\n","        'image/source_id': dataset_util.bytes_feature(filename),\n","        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","        'image/format': dataset_util.bytes_feature(image_format),\n","        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","        'image/object/class/label': dataset_util.int64_list_feature(classes),\n","    }))\n","    return tf_example\n","\n","\n","def main(_):\n","\n","    writer = tf.python_io.TFRecordWriter(args.output_path)\n","    path = os.path.join(args.image_dir)\n","    examples = xml_to_csv(args.xml_dir)\n","    grouped = split(examples, 'filename')\n","    for group in grouped:\n","        tf_example = create_tf_example(group, path)\n","        writer.write(tf_example.SerializeToString())\n","    writer.close()\n","    print('Successfully created the TFRecord file: {}'.format(args.output_path))\n","    if args.csv_path is not None:\n","        examples.to_csv(args.csv_path, index=None)\n","        print('Successfully created the CSV file: {}'.format(args.csv_path))\n","\n","\n","if __name__ == '__main__':\n","    tf.app.run()"]}]}